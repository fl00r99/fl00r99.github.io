<!DOCTYPE html>
<html lang="en">
<style>
  * {
    font-family: Arial, sans-serif;
  }
</style>
<head>
    <meta charset="utf-8">
    <link rel="stylesheet" type="text/css" href="css/styles.css">
    <title>what</title>
</head>
<body>

  <div class="textbox">
    <div class="scrollbar">
      <p>ik moet even denken of misschien niet denken maar gewoon schrijven
        nu wilde ik wel dat mijn schijf open ging want er is een limiet aan hoe veel een mens kan schrijven uit het niks</p>
        
      </div>
  </div>
  <marquee behavior="scroll" direction="left">ik kan uitleggen aan niemand of aan degene die dit uiteindelijk leest wat neural netwerken doen of toch degene die ik ken dus ja er zijn verschillende netwerken of wat men tegenwoordig ‘AI’ noemt dus er zijn LLMS, large language models er zijn GANS, generative adversarial networks, en er zijn diffusion-models, waar stable diffusion het meest bekende er van is. Image classifiers bestaan ook zoals CLIP maar ik ben even vergeten waarvoor de afkorting van CLIP staat. Jezus ik ben echt moe ik zou echt goed kunnen slapen de trein rijdt ook trager nu en hij hobbelt minder maar er zat wel lactose in de ijskoffie. Vqgan bestond ook of ja de combinatie van clip en vqgan en die was echt wel revolutionair want, ja juist OpenAI bestaat die zijn een AI bedrijf en eerst waren die van joepie alles moet toegankelijk zijn hier is onze code maar dan later kwamen ze daar toch op terug dus alleen GPT2 en CLIP waren open source geloof ik, (gpt2 is de voorloper van chatgpt en een voorbeeld van een LLM)
    de lactose in de ijskoffie is relevant want ik ben lactose intolerant dus dat is niet goed met de misselijkheid dus het probleem is niet opgelost maar het was wel lekker
    maar ja dus terug over clip en vqgan, openai, toen ze niet meer open waren hadden een model gemaakt en dat heette DALL-E en dat was getraind op text-image pairs (wat zou de vertaling daarvan zelfs in het nederlands zijn), dus je kon h
    ik herinner me een droom heel vaag over een trein was het over een trein of moet ik nu aan een trein denken omdat ik op een trein zit?
    Maar ja je kon het ding dus een zin geven en dan spuwde het een beeld uit en joepie keicool revolutionair maar niemand kon er zijn eigen ding mee doen want het was niet open source
    clip en vqgan was de opensource/ gehackte versie van DALL-E en een van de eerste super toegankelijke manieren om om te gaan met AI want dat was in een google colab notebook gemaakt door katherine crowson en dan moest jen ietzelf coderen maar gewoon op een paar knoppen duwen
    ah ja ik ging ook nog uitleggen hoe de rest werkte pff ja met GANS die hebben een generator en een discriminator en de discriminator heeft in feite al heel de dataset gezien dus die weet hoet alles er uit ziet maar de generator weet dat niet dus die spuwt de hele tijd noise uit maar soms zit er dus noise bij die meer op de originele data lijkt dus dat houdt de discriminator voor de gek en zo trainen ze elkaar want uiteindelijk krijgt die discriminator wel door dat het maar noise is ofzo dus dan gaat die beter kijken
    of ja beeldt u gewoon alstublieft in dat ze ogen hebben dan is het gemakkelijker te begrijpen </marquee>
  <div class="navigation-buttons">
    <a href="005.html">vorige</a>
    <a href="transformer.html">vorige</a>
    <a href="007.html">volgende</a>
  </div>

</body>
</html>
